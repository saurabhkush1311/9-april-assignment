{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?\n",
    "\n",
    "Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Bayes' theorem is a fundamental concept in probability theory and statistics. It describes how to update the probability of an event based on new evidence or information. The theorem is named after the Reverend Thomas Bayes, who introduced the concept.\n",
    "\n",
    "Q2. The formula for Bayes' theorem is:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "where:\n",
    "- P(A|B) is the probability of event A occurring given that event B has occurred.\n",
    "- P(B|A) is the probability of event B occurring given that event A has occurred.\n",
    "- P(A) is the probability of event A occurring.\n",
    "- P(B) is the probability of event B occurring.\n",
    "\n",
    "Q3. Bayes' theorem is used in practice in various fields, including statistics, machine learning, and data analysis. It is particularly useful in situations where there is prior knowledge or beliefs about the probability of certain events, and new evidence is obtained to update those probabilities. Bayes' theorem is used in Bayesian inference, which allows for the estimation of unknown parameters based on observed data.\n",
    "\n",
    "Q4. Bayes' theorem and conditional probability are closely related. Bayes' theorem provides a way to calculate conditional probabilities. In the formula, P(A|B) represents the probability of event A occurring given that event B has occurred, which is a conditional probability. The theorem allows us to update our prior beliefs about the probability of event A based on new evidence or information (represented by P(B|A)).\n",
    "\n",
    "Q5. The choice of which type of Naive Bayes classifier to use depends on the nature of the data and the assumptions made about the independence between features. The three main types of Naive Bayes classifiers are:\n",
    "- Gaussian Naive Bayes: It assumes that the features follow a Gaussian (normal) distribution.\n",
    "- Multinomial Naive Bayes: It is used for discrete features that have a multinomial distribution, such as word counts in text classification.\n",
    "- Bernoulli Naive Bayes: It is suitable for binary features, where each feature is either present or absent.\n",
    "\n",
    "The choice depends on the specific problem and the characteristics of the data. Gaussian Naive Bayes is often used for continuous data, while Multinomial and Bernoulli Naive Bayes are commonly used in text classification tasks.\n",
    "\n",
    "Q6. To predict the class of the new instance using Naive Bayes, we need to calculate the conditional probabilities for each class based on the given feature values and use Bayes' theorem to determine the most probable class.\n",
    "\n",
    "Given the table of frequencies:\n",
    "\n",
    "Class | X1=1 | X1=2 | X1=3 | X2=1 | X2=2 | X2=3 | X2=4\n",
    "------|------|------|------|------|------|------|------\n",
    "A     |  3   |  3   |  4   |  4   |  3   |  3   |  3\n",
    "B     |  2   |  2   |  1   |  2   |  2   |  2   |  3\n",
    "\n",
    "Assuming equal prior probabilities for each class, we can calculate the conditional probabilities for each class based on the given feature values. For example, to calculate P(X1=3|A), we divide the frequency of X1=3 in class A (4) by the total frequency of class A (20). Similarly, we calculate the conditional probabilities for the other feature values and classes.\n",
    "\n",
    "Then, we calculate the posterior probabilities for each class using Bayes' theorem:\n",
    "\n",
    "P(A|X1=3, X2=4) = (P(X1=3|A) * P(X2=4|A) * P(A)) / P(X1=3, X2=4)\n",
    "P(B|X1=3, X2=4) = (P(X1=3|B) * P(X2=4|B) * P(B)) / P(X1=3, X2=4)\n",
    "\n",
    "Since we assumed equal prior probabilities for each class, P(A) = P(B) = 0.5.\n",
    "\n",
    "Next, we calculate the joint probabilities P(X1=3, X2=4) by summing the corresponding conditional probabilities for each class:\n",
    "\n",
    "P(X1=3, X2=4) = P(X1=3, X2=4|A) * P(A) + P(X1=3, X2=4|B) * P(B)\n",
    "\n",
    "Finally, we substitute the values into the equations and compare the posterior probabilities to determine the most probable class for the new instance.\n",
    "\n",
    "Please note that to complete the calculation, we need the conditional probabilities for each feature value and class. Based on the provided table, these probabilities are not explicitly given, so I cannot provide the exact prediction without further information."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
